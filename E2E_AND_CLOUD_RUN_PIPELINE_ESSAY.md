# E2E Testing and Cloud Run Pipeline: A Comprehensive Overview

## Understanding Real-Time Stock Analysis Through Browser Testing

The MCP Finance platform employs an end-to-end (E2E) testing strategy using Playwright to verify that real stock market data flows correctly from a user's browser through a cloud-based backend and back again without any mock data or synthetic results. These tests validate all nine MCP (Model Control Protocol) tools—including analyze_security, analyze_fibonacci, get_trade_plan, compare_securities, screen_securities, scan_trades, portfolio_risk, morning_brief, and options_risk_analysis—by simulating actual user interactions with the frontend. The E2E test pipeline begins with authentication through Clerk, proceeds to the MCP Control Center page, fills in real stock symbols like AAPL or MSFT, and triggers API calls that execute on the Cloud Run backend. Throughout this process, the tests verify that genuine market data appears in the results rather than hardcoded placeholder values, ensuring the system's integrity and reliability for users who depend on accurate financial analysis. This approach represents a critical quality assurance mechanism that confirms the entire stack—from React frontend to FastAPI backend to real-time yfinance data integration—works seamlessly together.

## The Complete E2E Testing Flow: From Browser to Results

The E2E test execution follows a well-defined six-phase process that mirrors how actual users interact with the platform. In Phase 1, the Playwright browser automation tool authenticates with Clerk, establishing a secure session for the test user. Phase 2 navigates to the /mcp-control route, where the React component renders the MCP Control Center interface containing the tool selector, parameter form, and results display area. During Phase 3, the test programmatically selects a tool (such as analyze_security) and fills in parameters like the stock symbol and analysis period. Phase 4 triggers the critical execution step—clicking the Execute button—which fires a POST request to /api/gcloud/execute, containing the tool name and parameters as a JSON payload. This request travels through the Next.js API route layer, which verifies user authentication, checks tier permissions (free/pro/max), and forwards the request to the Cloud Run MCP server running in Google Cloud. Phase 5 captures the results as they return through the API and render in the browser's Results Display component, showing real stock prices, technical signal counts, and execution timing. Finally, Phase 6 applies Playwright assertions to verify that the data is genuine—checking for real price patterns like "$182.45" using regex, confirming the absence of mock data indicators like the word "mock" or "placeholder", and validating that execution times fall within realistic ranges (500ms to 45 seconds). This systematic validation approach ensures no hidden failures can slip through to production, guaranteeing users always receive authentic market analysis.

## Cloud Run Pipeline Architecture: From Development to Production Deployment

The cloud infrastructure supporting MCP Finance follows a sophisticated multi-stage pipeline that seamlessly transitions code from local development environments through automated testing and into production Cloud Run services. When a developer commits code to the GitHub main branch, a webhook automatically triggers GitHub Actions, which runs a comprehensive CI/CD workflow including dependency installation via mamba (the fast conda package manager), code linting and type-checking with TypeScript, unit test execution, and Playwright E2E tests against a staging environment. Upon successful test completion, the workflow builds a Docker container image containing the Python FastAPI backend with all MCP tools compiled and dependencies bundled. This image gets pushed to Google Container Registry (GCR) and then deployed to Cloud Run, Google's managed container service that auto-scales from zero to 100 instances based on incoming traffic. The production Cloud Run service exposes nine REST API endpoints—/api/analyze for technical analysis, /api/fibonacci for Fibonacci levels, /api/compare for security comparison, /api/screen for universe screening, /api/scan for trade scanning, /api/portfolio-risk for portfolio assessment, /api/morning-brief for market briefings, /api/options-risk for options analysis, and supporting endpoints—each capable of fetching real-time stock data from yfinance and performing complex mathematical calculations on hundreds of technical indicators. Simultaneously, the Next.js frontend deploys to Vercel, a specialized platform for React applications that handles server-side rendering, API route proxying, and automatic scaling. Both systems connect via environment variables: the frontend sets MCP_CLOUD_RUN_URL to point to the Cloud Run service endpoint, ensuring all user requests properly route to the backend. This architecture enables the platform to scale globally, handle millions of concurrent users, and maintain 99.95% uptime through managed cloud services rather than requiring manual server administration.

## Request-Response Lifecycle: How Data Flows Through the System

Understanding the complete journey of a single user request illuminates how the platform delivers real-time financial analysis. When a user selects a stock symbol like "AAPL" and clicks Execute in their browser, the frontend sends a POST request to /api/gcloud/execute containing the tool name (e.g., "analyze_security"), parameters (symbol, period), and AI preference flags. The Next.js API route receives this request, authenticates the user using their Clerk JWT token, verifies their subscription tier to determine feature access, checks rate limits to prevent abuse, and creates a database record in the mcpRuns table to track this analysis. The route then forwards the request to the Cloud Run MCP server at the configured endpoint, passing along the parameters as JSON. The Cloud Run service receives the request and executes the corresponding Python function—for analyze_security, this means fetching six months of historical OHLCV data from yfinance, calculating 150+ technical indicators including moving averages (SMA, EMA), oscillators (RSI, MACD, Stochastic), volatility measures (Bollinger Bands, ATR), volume indicators (OBV, VWAP), trend measures (ADX, Ichimoku), and price patterns. The system generates trading signals by applying predefined rules to these indicators, such as detecting a Golden Cross when the 50-day moving average crosses above the 200-day moving average. If the user requested AI insights (available in Pro tier), the Cloud Run service optionally calls Google's Gemini API to generate natural language analysis of the technical data. The complete analysis package—including the stock symbol, current price, 150 signals with descriptions and strength ratings, trade plan recommendations with entry/stop/target levels, and optional AI commentary—returns as structured JSON to the Next.js API route, which stores the results in the database and returns them to the browser. The React ResultsDisplay component receives this data and renders it visually with price cards, signal count badges, top signal lists, and execution timing information. Throughout this entire flow, the platform never uses mock data or hardcoded values; every number comes from real market sources, ensuring users see authentic information for their trading decisions.

## Conclusion: The Importance of Real Data Verification in Financial Software

The E2E testing infrastructure and Cloud Run pipeline represent more than just technical architecture—they embody a fundamental commitment to data integrity in financial software where accuracy directly impacts users' trading decisions and real money. By automating tests that verify real stock prices, actual technical signals, and genuine API responses flowing through the entire system, MCP Finance ensures that no mock data, placeholder values, or hardcoded results can accidentally be deployed to production. The multi-stage pipeline from local development through GitHub Actions CI/CD, Docker containerization, Google Container Registry, and finally Cloud Run deployment creates multiple checkpoints where integration failures can be caught and prevented. The 60-second test timeouts and 45-second execution time limits ensure that performance remains acceptable even under load, while the verification of real price patterns using regex matching ($XXX.XX format) and exclusion of mock indicators ("mock", "placeholder", "hardcoded") demonstrate explicit quality gates. This systematic approach proves that the frontend, Next.js API routes, Cloud Run backend, and yfinance data sources work perfectly together, delivering real-time market analysis reliably and safely. For traders relying on the platform for daily decision-making, this level of automated quality assurance provides confidence that the numbers they see are authentic, the signals are accurate, and the system will perform predictably under production conditions.
